---
title: 网络IO
typora-root-url: ../
date: 2021-04-24 15:39:35
tags:
- IO
categories:
- [网络通信,网络IO]
---

对网络IO的知识进行简单了解

<!--more-->

# 一、基本概念

## 1.同步、异步；阻塞、非阻塞

对于**IO上面的理解**

同步异步描述的是**用户线程**同**内核**的两个方面的交互状态

- **同步**指用户线程发起IO请求后，需要**等待或者轮询内核IO操作完成**后，才能继续执行
- **异步**是指用户线程向内核发起IO请求后，依旧可以继续执行，而**内核的IO操作完成后，会通知用户线程或者执行用户线程注册的回调函数**

阻塞和非阻塞描述的是**用户线程**调用IO操作的方式

- **阻塞**指**IO操作彻底完成后**才返回用户空间

- **非阻塞**指IO操作被调用时立即返回一个**状态值**，不需要IO操作彻底完成



在更高层面上理解的话，**同步、异步是两个对象之间的关系，而阻塞、非阻塞是一个对象的状态**。

比如对于通信，同步和异步是指：发送方和接收方是否协调步调一致；对于线程，是指两个线程的运行是否相关，会被阻塞

而阻塞和同步、异步的关系，**阻塞可以是实现同步的一种手段**。例如两个东西需要同步，一旦出现不同步情况，我就阻塞快的一方，使双方达到同步



一篇转载文章理解

[转载至灵剑](https://www.zhihu.com/question/19732473/answer/117012135)

一个网络包从应用程序A发到另一台电脑上的应用程序B，需要经历：

1. 从A的业务代码到A的软件框架
2. 从A的软件框架到计算机的操作系统内核
3. 从A所在计算机的内核到网卡
4. 从网卡经过网线发到交换机等设备，层层转发，到达B所在计算机的网卡
5. 从B所在计算机的网卡到B所在计算机的内核
6. 从B所在计算机的内核到B的程序的用户空间
7. 从B的软件框架到B的业务代码

这个层级关系就像是过程调用一样，前一级调用后一级的功能，后一级返回一个结果给前一级（比如：成功，或者失败）。只有在单独一级的调用上，可以说同步还是异步的问题。所谓同步，是指调用协议中结果在调用完成时返回，这样调用的过程中参与双方都处于一个状态同步的过程。而异步，是指调用方发出请求就立即返回，请求甚至可能还没到达接收方，比如说放到了某个缓冲区中，等待对方取走或者第三方转交；而结果，则通过接收方主动推送，或调用方轮询来得到。

从这个定义中，我们看，首先1和7，这取决于软件框架的设计，如果软件框架可以beginXXX，然后立即返回，这就是一种异步调用，再比如javascript当中的异步HTTP调用，传入参数时提供一个回调函数，回调函数在完成时调用，再比如协程模型，调用接口后马上切换到其他协程继续执行，在完成时由框架切换回到协程中，这都是典型的异步接口设计。

**而2和6，其实都需要调用方自己把数据在内核和用户空间里搬来搬去，其实都是同步接口，除非是IOCP这样的专门的异步传输接口，所以这一级其实是同步的，阻塞与非阻塞的区别其实是影响调用接口的结果（在特定条件下是否提前返回结果），而不是调用方式。**

3和5，内核一般通过缓冲区，使用DMI来传输数据，所以这一步又是异步的。

4，以太网是个同步时序逻辑，随信号传输时钟，必须两边设备同时就绪了才能开始传输数据，这又是同步的。

总结来说，讨论究竟是异步还是同步，一定要严格说明说的是哪一部分。其他答主说非阻塞是同步而不是异步，这毫无疑问是正确的，然而说某个框架是异步IO的框架，这也是正确的，因为说的其实是框架提供给业务代码的接口是异步的，不管是回调还是协程，比如说我们可以说某个库是异步的HTTPClient，并没有什么问题，因为说的是给业务代码的接口。由于通常异步的框架都需要在2中使用非阻塞的接口，的确会有很多人把非阻塞和异步混为一谈。



## 2.一个网络通信过程

**一个服务端处理请求的过程**

![image-20210424170224633](/images/image-20210424170224633.png)

所以关于网络中的数据输入操作主要包含两个过程

- 等待数据准备好，从网卡复制到内存缓冲区
- 从内核向进程的用户空间复制数据

# 二、常见IO模型

## 同步阻塞IO

通过阻塞实现同步，用户在内核进行IO操作时阻塞

![image-20210507153854260](/images/image-20210507153854260.png)

用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作。

由于用户需要等待read将socket中的数据读取到buffer后，才继续处理接收的数据。整个IO请求的过程中，用户线程是被阻塞的，这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够。

这个时候要实现高并发就是我们常见的多线程模型

## 同步非阻塞IO

此时用户线程在发起IO请求后立即返回，为了实现同步，用户线程执行轮询操作直到IO操作完成

![image-20210507154448923](/images/image-20210507154448923.png)

这里socket是非阻塞的方式，因此用户线程发起IO请求时立即返回。但并未读取到任何数据，用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行。

可见该方法避免了用户线程阻塞，但是不断的轮询会消耗大量的CPU资源，一般很少使用。如果在线程轮询消耗远小于线程阻塞、唤醒、切换的消耗，可以考虑使用，类似于Java synchronized用自旋锁优化的过程



在高并发情况下，存在C10K问题，每次循环遍历所有客户端，会花费时间不断反复执行read系统调用，特别在不是所有客户端都ready的情况下，消耗大量CPU时间，即每循环内O(n)的系统调用

## IO多路复用

### **select**

select是内核提供的多路分离函数，可以使用其实现IO端口的复用

下面是Linux中的select设计

关键有两个结构体

```c
fd_set
timeval
```

其中**fd_set**可以认为是一个位图，每一位标志相应大小文件描述符（每一个文件描述符同一个socket对应），fd_set主要有三种类型：readfds、writefds、errorfds，对应可读、可写、异常等情况

**timeval**主要记录时间

调用select函数时，参数如下

```c
int select(int maxfdp,fd_set *readfds,fd_set *writefds,fd_set *errorfds,struct timeval *timeout);
```

其中maxdp是所有文件描述符的范围，为fd_set中所有文件描述符的最大值加1

中间三个fds分别代表监控读、写、错误异常文件，可以传null值表示不关心

最后的timeout是select的超时时间：

- 为NULL：将select置于阻塞状态，一定等到监视文件描述符集合中某个文件描述符发生变化为止
- 为0，就变成一个纯粹的非阻塞函数，不管文件描述符是否有变化，都立刻返回继续执行，文件无变化返回0，有变化返回一个正值
- 正值，是等待的超时时间，即 select在timeout时间内阻塞，超时时间之内有事件到来就返回了，否则在超时后不管怎样一定返回，返回值同上述。

最后就可以对select的工作流程进行概述：

select将有多个文件描述符传递给内核，内核监控这些文件描述符直到一个或多个文件描述符变成可用状态，在返回这些可用的状态，程序再对这些可用状态进行读写操作，是同步的。

select也是一个系统调用，在高并发情况下，利用select可用大幅度减少系统调用的次数，对比上面的同步非阻塞模型，每次循环执行一个select，内核主动遍历这些文件描述符O（n），注意区别在于这里O（n）的遍历**不是系统调用**，进而比之前的模型更优化了

但是该方法也有一些问题：

- 每次select传递大量的文件描述符
- 内核主动遍历这些文件描述符时间复杂度高，cpu浪费

采用epoll正是对这两方面的优化

### epoll

**优化原理**

epoll在内核开辟一片空间，添加的文件描述符就放在这片空间，避免了select重复传递大量文件描述符的问题

此外epoll内核和用户共用一片内存，将状态改变的文件描述符放置在这片区域，程序再从这片区域中读取这些可读可写的文件描述符，发生同步读写

此时内核通过**事件驱动**将内核空间内的状态ready的文件描述符放置到共享的内存区域供程序读写，这个时间复杂度是**O(1)**

这个事件驱动原理和前面的网络通信过程有关：

当客户端的数据发送到硬件网卡的缓存上，网卡收到数据后放置到内核缓存区，这时网卡会通过硬中断中断CPU，CPU通过回调知道是哪个文件描述符状态改变，再移动到共享区域。这个时候CPU不需要主动遍历这些文件描述符，而是通过中断知道哪些文件描述符准备完毕，更少的浪费了CPU

**Linux实现**

epoll在Linux上的实现主要和几个函数有关

```
epoll_create 开辟添加文件描述符的空间，记fd1
epoll_ctl 对文件描述符进行增加、删除、修改监听事件 在fd1上操作
epoll_wait 阻塞进程，等待事件的产生
```

这些方法都是系统调用方法

方法使用步骤如下

- 当某个进程调用epoll_create方法时，内核会创建一个eventpoll对象，其内维护一个等待队列（为了便于插入删除，采用的是双向队列，同时采用红黑树做索引）

- 创建一个eventpoll对象，可以用epoll_ctl添加或删除所要监听的socket

- 进程执行执行了epoll_wait，就绪列表没有数据进程阻塞；当socket收到数据后，中断程序会给eventpoll的“就绪列表”添加socket引用，同时也会唤醒对对应的进程（执行了epoll_wait）



### Reactor模式

Reactor模式需要底层的同步事件分离器，比如上文的select或者epoll。或者说，该模式是采用了select或者是epoll编程的一种应用方式，具体工作原理如下图

![image-20210511164127269](/images/image-20210511164127269.png)

Reactor基于事件驱动的，它有一个或多个并发输入源，有一个Reactor，其管理连接的socket的注册、删除与转发，让socket和一个对应event handler关联；然后Reactor再调用select或者epoll对对应的socket进行处理，等待相应的事件发生，事件发生后会通知Reactor，对发生事件的socket调用特定的event handler响应事件

下图是基于select的Reactor实现

![image-20210509155140363](/images/image-20210509155140363.png)

## 信号驱动 I/O

应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。

相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。

## 异步IO

用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

“真正”的异步IO需要操作系统更强的支持，需要操作系统实现异步读API。在IO多路复用模型中，事件循环将文件句柄的状态事件通知给用户线程，由用户线程自行读取数据、处理数据。而在异步IO模型中，当用户线程收到通知时，数据已经被内核读取完毕，并放在了用户线程指定的缓冲区内，内核在IO完成后通知用户线程直接使用即可。

## IO模型比较

体会了几个网络IO模型的概念后，再整体了解同步异步IO以及几大模型之间的区别

- 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。
- 异步 I/O：第二阶段应用进程不会阻塞。

同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用 ，它们的主要区别在第一个阶段。

非阻塞式 I/O 、和异步 I/O 在第一阶段不会阻塞。

只有异步IO第二个阶段不会阻塞



