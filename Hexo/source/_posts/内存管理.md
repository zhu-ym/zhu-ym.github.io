---
title: 内存管理
typora-root-url: ../
date: 2020-12-29 09:11:20
tags:
 - 内存管理
categories:
 - [操作系统,现代操作系统]
---

​		本文简单介绍操作系统内存管理的发展，最后再重点讲解如今使用得最多的虚拟内存技术及其实现。

<!--more-->

[TOC]



# 内存管理发展

存储器不可能无限大、快速、永久又价格低廉，综合考虑后，人们提出**分层存储器体系：**

- 快速、昂贵、容易失性的高速缓存（cache）
- 速度价格适中、也易失性的内存
- 低速廉价、非易失性的磁盘存储

而操作系统则通过存储管理器管理分层存储器体系

这里主要讲解分层存储器体系中**内层管理**

## 无存储器抽象

最早的存储器没有抽象，即意味着每一个程序直接访问物理内存

再此情况下，很难在内存中同时运行两个程序，我们的进程模型很难在这样的内存上实现，除非使用交换技术或者依靠硬件。

总之，进程直接访问内存可能带来以下问题：

- 破坏操作系统
- 难以实现程序并发

## 地址空间

**地址空间**是对存储器的抽象，其为进程创造了一抽象的内存。地址空间是一个进程可**以用于寻址内存**的一套地址集合，每个进程都有自己独立的地址空间。

地址空间的关键在于给每个进程自己独立的地址空间，并使其物理内存和其他物理内存地址不一致。

显然，这个问题最简单可以通过简单映射解决，如**动态重定位：**简单将每个进程的的地址空间映射到物理内存不同部分。该方法结合基址寄存器和界限寄存器可以很好的工作：基址寄存器记录进程起始物理地址，界限寄存器记录进程长度，每次进程访问内存，CPU硬件将地址发到内存总线前，自动把基址值加到进程发出的地址上，在检查其是否超过界限寄存器的界限值，如果超过，产生错误并中止访问。

上诉方案有一个问题，内存不够大，不断为进程分配地址，如果内存空间满了怎么办？内存很难保存所有进程。

内存超载有两个解决方案，较简单的**交换技术**和更常用的**虚拟内存**

**交换技术**大致思想是把一个进程调入内存，运行一段时间后再把它存回磁盘

交换技术其内存是**快式管理**，一个进程分配一块地址，那当新分配一个进程的地址时，就和Java虚拟机中的内存分配有一些共同之处：都可以用空闲链表来选择不同算法进行动态内存分配（首次适配、下次适配、最佳适配、最差适配、快速适配），所以自然也都存在空间碎片问题

除了使用记录已分配内存段和空闲内存段的链表进行内存分配和管理，还可以通过划分内存为一定大小的分配单元，再用位图进行管理。下图是现代操作系统上位图和链表的大致结构

![image-20201229104028181](/images/image-20201229104028181.png)

位图的缺点是查找指定的大小0块比较费时，链表主要是会产生空间碎片，需要进行合并操作

**虚拟内存**技术对地址空间再进行细化、采用了不同于块式管理的方案，很适合在多道程序设计系统中使用。下面详细介绍。

# 虚拟内存

虚拟内存对地址空间再进行细化，分成多个块，每一块称为一**页**或者**页面**，每页有连续的地址范围，映射到物理内存（物理内存不要求连续）。最重要的是，进程的运行不需要所有页都在内存中，当程序引用到不在物理内存中的页时，会将缺失的部分装入物理内存并重新执行失败的指令。

## 分页技术

大多虚拟内存采用分页的技术

进程产生的地址称为**虚拟地址**，它们构成**虚拟地址空间**，虚拟地址空间按固定大小划分成**页面**，页面对应物理内存中的单元称为**页框**

最简单的虚拟地址一般由：**虚拟页号**+**偏移量**组成

在内存中一般有一个**页表**，其内部有很多页表项，典型页表项结果如下：

![image-20201229113257172](/images/image-20201229113257172.png)

现在可以具体描述采用分页技术的内存访问流程了

在没有虚拟内存的计算机上，系统直接把虚拟地址送到内存总线，而这里将其送到**内存管理单元（MMU）**。之后MMU再访问内存中的**页表**，根据虚拟地址的虚拟页号，找到页表中的页表项，得到页框号，最后将页框号替代虚拟地址中的虚拟页号，得到内存物理地址，再访问内存。注意以上操作要访问**两次内存**。

如果内存中不存在该页面就会产生**缺页中断**，CPU陷入操作系统，操作系统找到很少使用的页框写入磁盘（看是否修改），随后把需要的页框读入，修改映射关系，然后重新启动引起中断的指令。

了解分页技术的基本机制后我们要对其优化

- 第一访问内存物理地址需要访问两次内存，我们要加快虚拟地址到物理地址的映射
- 第二如果虚拟地址空间很大，我们需要很大的页表

**块表**

针对第一个问题，如果选择将内存中页表副本载入寄存器，如果页表大，代价就大，并且不同进程上下文切换装载整个页表也会降低性能。

基于以下假设：”大多数程序对少量页面进行多次访问“，我们通常在MMU中设置一小型硬件设备**转换检测缓冲区**（TLB），也叫**快表**，通过保存少量类似于页表项的表项，这些表项一般是常用的。

当将虚拟地址放入MUU进行转化时，先判断TLB中是否存在该虚拟页面，存在不需要访问页表直接转化访问对应物理地址。若不存在，则进行正常的页表查询，并从TLB中淘汰一个表项，复杂到内存的页表项中。

当然TLB也可以用软件进行管理，将TLB表项由操作系统显式装载，当TLB访问失效时，不再由MMU到页表查询，而生成TLB失效将问题给操作系统解决。

有了快表，有时只要访问一次高速缓冲存储器，一次内存，这样可加速查找并提高指令执行速度。

**多级页表**

多级页表用来解决巨大的虚拟地址空间问题。

现代计算机使用至少32位的虚拟地址，页面大小固定，表项就会多，页表就会很大。当进程的虚拟空间大，但是实际使用内存不是那么多时，使用多级页表可以节约内存。

以二级页表为例，将页表划分为顶级页面和二级页表，顶级页面包含二级页表的地址和，二级页表就同之前介绍的页表类似，将进程产生的虚拟地址解释为：PT1+PT2+偏移量。

此时MMU先根据PT1的索引找到二级页表的地址，再和上述过程一样通过PT2和二级页面定位具体地址。这导致二级页表可以不用连续存储了，很容易分配空间，其次，当进程使用很大的虚拟地址空间，但实际并没有用完这片虚拟地址空间时，只会产生需要的页表，空闲区直接在顶级页表中标记为不在，当访问时强制产生缺页中断，交于操作系统处理，比如杀死进程。

由于计算机组成原理里面无处不在的局部性原理：我们可以知道，第一，某些二级页表可以不存在；第二，二级页表可以不在主存，这样就可以节约内存

最后总结多级页表特点

- 二级页表分配可以离散，偏于分配
- 节约内存
- 比一级页表多了一次访问

## 页面置换算法

前面说到发生缺页中断时，操作系统必须在内存选择一个页框换出，在方便调入需要的页框。

如果选择频繁使用的页框换出内存，又短时间内被调入，显然会增加开销，这时针对页面的选择有不同的调度算法

**1.最优页面置换算法（OPT）**

每次选择之后最晚被使用的页面换出，可以保证获得最低的缺页率，但很难实现，因为系统不知道各个页面下次什么时候被访问，只是作为一个衡量其他算法的指标

**2.最近未使用算法（NRU）**

利用前面说到的页表项**访问位**R和**修改位**M的数据

R位利用时钟中断定期清零

最后分成四种情况，按1）未访问、未修改；2）未访问、已修改；3）已访问、未修改；4）已访问、已修改 依次分级，越在前越容易被置换

**3.FIFO页面置换算法**

选择换出的页面是最先进入的页面。该算法会将那些经常被访问的页面换出，导致缺页率升高

用一队列维护

**4.第二次机会页面置换算法**

对FIFO的优化，对于FIFO将要换出的算法、如果R位位1，置0放队尾，为0就换出

**5.时钟页面置换算法**

对第二次机会算法的优化，采用循环链表，不用移动链表，而是直接移动指向页面的指针

**6.最近最少为未使用页面置换算法（LRU）**

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

此外可以通过硬件实现，要求有一64位计数器C，每条指令后C+1，在表项中保存该计数器值的域，选择最小换出

LRU非常接近OPT

**7.最不常用算法（NFU）**

用一个软件计数器与页面管联，每次时钟中断时将页面R位加到其计数器上，发生缺页中断时，置换计数器值最小的算法

希望用NFU接近LRU，但是明显页面在几个时钟前和最近一个时钟被访问都是相同的权重，无法区别

**8.老化算法**

对NFU优化，每次加R时先将计数器右移一位，在将R放在左端，即加大最近被访问页面的权重。

非常接近LRU算法，只是无法区别同一个时钟内页面的先后

**9.工作集页面置换算法**

我们称一个进程当前正在使用的页面集合称为它的**工作集**，当整个工作集被装入内存，缺页中断少，反正多，不少分页系统会跟踪进程的工作集，确保程序运行以前，预先装入工作集，减少中断。

该算法当发生缺页中断时，淘汰一个不在工作集中的页面。

难点是确定工作集：工作集可以是最近k次内存访问用过的页面集合，也可以是最近一段时间t使用的集合,用后者工作集便于计算。我们采用后者，后者便于实现

此时表项中有上次近似使用时间和访问位至少两个信息，当发生缺页中断，遍历表项，如果R位为1，将当前时间写入上次近似使用时间，如果R为0，生成时间小于t则认为该页面不再工作集中，用新的页面置换他，并更新剩余表项

如果出现特殊情况，生存时间均小于t，生存时间最长的页面淘汰

该算法要扫描整个页表

**10.工作集时钟页面置换算法**

结合了时钟算法和工作集，在工作集算法上添加了M位

每次缺页中断时，首先检查指针指向的页面。如果R位被置为1，该页面在当前时钟滴答中就被使用过，那么该页面就不适合被淘汰。然后把该页面的R位置为0，指针指向下一个页面，并重复该算法

在若R=0时，如果页面的生存时间大于t：如果该页面是干净的，直接置换。如果此页面被修改过，为了避免由于调度写磁盘操作引起的进程切换（但是可以当积累一定多页面写入后执行写操作），指针继续向前走，算法继续对下一个页面进行操作，希望找到旧的且干净的页面可以立即使用。

如果指针经过一圈返回它的起始点并且没有写操作，说明都在工作集，随便置换一个干净页面，不存在就当前页面；如果有写操作，继续之前算法。



总结：**LRU**很优秀，但是需要特殊硬件实现才能保证性能，这时可以采用**老化算法**用软件模拟LRU；基于工作集的算法，**工作集时钟算法**更优、更高效，实际运用中，可能老化算法和工作集时钟算法最重要、更优秀。

## 分段技术

从前面，我们了解每个进程都有自己的一个独立地址空间和控制线程，这片地址空间在虚拟内存中分成一个虚拟地址空间，一般这个虚拟地址空间用分页技术管理，只要通过虚拟地址的一个索引（多级页表可能多次）+偏移的手段就可以寻到物理地址。

如果程序都在这个独立的地址空间上工作，考虑到程序会生成一些可以动态扩张的块，这些块是动态扩张时，就可能出现分配给某个块的地址被装满、尽管其他块还有大量的空间。这可能让程序员管理这些块的扩张或者收缩很麻烦，所以提出了段的概念。

**段:**对进程的独立空间划分为多个段，更细化的认为每个段构成一段独立的地址空间，其可以独立的增长和缩小而不会影响其他的段。段不是定长的，也可以被铺满，但通常有比较大的上界。段是一个逻辑实体，并且应该为程序员所知，一个段可能包括一个过程、一个数组、一个堆栈但一般不包含多种不同类型的内容，程序员可以设置某个段为只读或者只执行等待对其进行保护。

在分页技术下，进程的整个地址空间就是一个线性地址空间，提出分段后，整个地址空间可能存在多个线性地址空间，所以程序员必须通过段号等手段找到其线性地址空间的位置，再通过段内地址找到实际的物理地址，认为其是二维的。

这里比较一下分页分段

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 目的不同：分页主要用于实现虚拟内存，从而获得更大的地址空间而不必购买物理存储器；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护

**段页式管理机制**：段页式管理机制结合了段式管理和页式管理的优点。程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页，其段与段之间以及段的内部的都是离散的。

